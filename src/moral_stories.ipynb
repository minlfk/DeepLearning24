{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22975,
     "status": "ok",
     "timestamp": 1736963133736,
     "user": {
      "displayName": "Min K",
      "userId": "03608091801211494236"
     },
     "user_tz": -60
    },
    "id": "RhjaW9y4ERed",
    "outputId": "3e4d7515-e7de-4e73-be4f-bddc04958a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# For Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1736963175623,
     "user": {
      "displayName": "Min K",
      "userId": "03608091801211494236"
     },
     "user_tz": -60
    },
    "id": "9sfLQ_N2ERei",
    "outputId": "01753380-9716-48f4-cae4-f8ee2f80229a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/DeepLearning\n"
     ]
    }
   ],
   "source": [
    "# For Google Colab\n",
    "%cd /content/drive/MyDrive/Colab Notebooks/DeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 18423,
     "status": "ok",
     "timestamp": 1736963233438,
     "user": {
      "displayName": "Min K",
      "userId": "03608091801211494236"
     },
     "user_tz": -60
    },
    "id": "zXOC3ZrKGLRk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eugeniemk/Desktop/MA3/DeepLearning/project/DeepLearning24/dl_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import concatenate_datasets\n",
    "import sklearn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from utils import *\n",
    "from rag import KnowledgeBase\n",
    "from rag import BeliefGroups\n",
    "from rag import metric_exact_match\n",
    "from rag import metric_f1\n",
    "import csv\n",
    "from embeddings import similarities_passages\n",
    "from embeddings import similarities_norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrqzshRiGLRl"
   },
   "source": [
    "# Moral Stories dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1736963244832,
     "user": {
      "displayName": "Min K",
      "userId": "03608091801211494236"
     },
     "user_tz": -60
    },
    "id": "D05e884zERel"
   },
   "outputs": [],
   "source": [
    "from llm import *\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Eugenie's token\n",
    "#login('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')\n",
    "\n",
    "# Selim's token\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KjkBZs8GKiBO"
   },
   "outputs": [],
   "source": [
    "# Load Moral Stories dataset\n",
    "ds_moralstories = load_dataset(\"demelin/moral_stories\", \"cls-action+context+consequence-norm_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCMDZrj5KUaG"
   },
   "outputs": [],
   "source": [
    "# Pre-process dataset:\n",
    "#   ds is a list of tuples (elem1, elem2), where elem1 / elem2 corresponds to row in original datset\n",
    "#   with moral / immoral choice\n",
    "\n",
    "train_data = ds_moralstories[\"train\"]\n",
    "test_data = ds_moralstories[\"test\"]\n",
    "val_data = ds_moralstories[\"validation\"]\n",
    "\n",
    "ds_moralstories = concatenate_datasets([train_data, test_data, val_data])\n",
    "moral_ds = ds_moralstories.filter(lambda x: x['label'] == 1)\n",
    "immoral_ds = ds_moralstories.filter(lambda x: x['label'] == 0)\n",
    "\n",
    "zipped = list(zip(moral_ds, immoral_ds))\n",
    "\n",
    "ds = subset_ds(zipped, 1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r29aHYaXKj2I"
   },
   "outputs": [],
   "source": [
    "# Text embedding model: MinyLM\n",
    "model_embd = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1736963428495,
     "user": {
      "displayName": "Min K",
      "userId": "03608091801211494236"
     },
     "user_tz": -60
    },
    "id": "xx9_NvEaGLRn"
   },
   "outputs": [],
   "source": [
    "# Instanciation of Knowledge Base and belief groups\n",
    "bg = BeliefGroups((\"moral\", \"immoral\"))\n",
    "kb_embed = KnowledgeBase(beliefgroups = bg, dim = 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1919,
     "status": "ok",
     "timestamp": 1736963440302,
     "user": {
      "displayName": "Min K",
      "userId": "03608091801211494236"
     },
     "user_tz": -60
    },
    "id": "rTSiQJ0TEReo"
   },
   "outputs": [],
   "source": [
    "# Add passages (moral and immoral choices) to Knowledge Base\n",
    "passage_embeddings = []\n",
    "for elem in ds:\n",
    "    moral_choice = elem[0]['moral_action']\n",
    "    immoral_choice = elem[1]['immoral_action']\n",
    "    moral_embed = model_embd.encode(moral_choice)\n",
    "    immoral_embed = model_embd.encode(immoral_choice)\n",
    "    passage_embeddings.append((moral_embed, immoral_embed))\n",
    "\n",
    "for passage_index, passage_embd in enumerate(passage_embeddings):\n",
    "    kb_embed.add_item(passage_embd[0], passage_index, bg.groups[0])\n",
    "    kb_embed.add_item(passage_embd[1], passage_index, bg.groups[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736963452975,
     "user": {
      "displayName": "Min K",
      "userId": "03608091801211494236"
     },
     "user_tz": -60
    },
    "id": "aLpjdvh-GLRn"
   },
   "outputs": [],
   "source": [
    "# Choose distance metric\n",
    "distance_metric = 'l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qh1BZkdrJqp5"
   },
   "outputs": [],
   "source": [
    "# Evaluation of RAG:\n",
    "#   how often do we retrieve moral / immoral choices in Knowledge Base given a situation in the dataset\n",
    "recall_moral = 0\n",
    "recall_immoral = 0\n",
    "\n",
    "# Set the following to True if you want to see the wrong matchings\n",
    "print_wrong_matchings = True\n",
    "\n",
    "for i, elem in enumerate(ds):\n",
    "    query = elem[0]['situation'] + ' ' + elem[1]['intention']\n",
    "    retrieved_moral = kb_embed.retrieve(model_embd.encode(query), distance_metric, 'moral', k = 1)\n",
    "    retrieved_immoral = kb_embed.retrieve(model_embd.encode(query), distance_metric, 'immoral', k = 1)\n",
    "    if(retrieved_moral[0] == i):\n",
    "        recall_moral += 1\n",
    "    elif(print_wrong_matchings):\n",
    "        print(\"Situation: \" + query)\n",
    "        print(\"Pred: \" + ds[retrieved_moral[0]][0]['moral_action'])\n",
    "        print(\"GT: \" + ds[i][0]['moral_action'])\n",
    "\n",
    "    if(retrieved_immoral[0] == i):\n",
    "        recall_immoral += 1\n",
    "    elif(print_wrong_matchings):\n",
    "        print(\"Situation: \" + query)\n",
    "        print(\"Pred: \" + ds[retrieved_immoral[0]][1]['immoral_action'])\n",
    "        print(\"GT: \" + ds[i][1]['immoral_action'])\n",
    "\n",
    "recall = (recall_immoral + recall_moral) / (len(ds) * 2)\n",
    "recall_moral = recall_moral / len(ds)\n",
    "recall_immoral = recall_immoral / len(ds)\n",
    "\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"recall_moral: {recall_moral}\")\n",
    "print(f\"recall_immoral: {recall_immoral}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QudAt6HRHHMH"
   },
   "source": [
    "### Pipeline for TINY_LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjxNUayOJosX"
   },
   "outputs": [],
   "source": [
    "# TINY LLAMA\n",
    "model_name = TINY_LLAMA\n",
    "task = \"text-generation\"\n",
    "similarity_metric = \"cosine\"\n",
    "\n",
    "# moral norms to respect in dataset\n",
    "norms = [tuple_dict['norm'] for tuple_dict, _ in ds]\n",
    "\n",
    "# all passages\n",
    "passages = [[tuple_dict1['moral_action'], tuple_dict2['immoral_action']] for tuple_dict1, tuple_dict2 in ds]\n",
    "\n",
    "model = llm(model_name, task = task)\n",
    "\n",
    "results = model.run_on_ds(ds, kb_embed, model_embd, distance_metric, kb_embed.beliefgroups.groups, trim=True)\n",
    "\n",
    "save_list(\"tinyllama\" + \"_results.csv\", results)\n",
    "\n",
    "keys = [\"pluralistic\", \"dummy_pluralistic\", \"vanilla\", \"moral\", \"immoral\"]\n",
    "scores_passages = {}\n",
    "scores_norms = {}\n",
    "for key in keys:\n",
    "    sim_with_passages = similarities_passages(model_embd, results, key, passages, similarity_metric)\n",
    "    scores_passages[key] = sim_with_passages\n",
    "\n",
    "    sim_with_norms = similarities_norms(model_embd, results, key, norms, similarity_metric)\n",
    "    scores_norms[key] = sim_with_passages\n",
    "\n",
    "save_similarities(\"tinyllama\" + \"_sim.csv\", scores_passages)\n",
    "save_similarities(\"tinyllama\" + \"_sim_w_norms.csv\", scores_norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDkSAhtQKl7M"
   },
   "source": [
    "### Pipeline for Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RduAdsYnJkJy"
   },
   "outputs": [],
   "source": [
    "# GEMMA\n",
    "model_name = GEMMA\n",
    "similarity_metric = \"cosine\"\n",
    "\n",
    "# moral norms to respect in dataset\n",
    "norms = [tuple_dict['norm'] for tuple_dict, _ in ds]\n",
    "\n",
    "# all passages\n",
    "passages = [[tuple_dict1['moral_action'], tuple_dict2['immoral_action']] for tuple_dict1, tuple_dict2 in ds]\n",
    "\n",
    "model = llm(model_name)\n",
    "\n",
    "results = model.run_on_ds(ds, kb_embed, model_embd, distance_metric, kb_embed.beliefgroups.groups, trim=True)\n",
    "\n",
    "save_list(\"gemma\" + \"_results.csv\", results)\n",
    "\n",
    "keys = [\"pluralistic\", \"dummy_pluralistic\", \"vanilla\", \"moral\", \"immoral\"]\n",
    "scores_passages = {}\n",
    "scores_norms = {}\n",
    "for key in keys:\n",
    "    sim_with_passages = similarities_passages(model_embd, results, key, passages, similarity_metric)\n",
    "    scores_passages[key] = sim_with_passages\n",
    "\n",
    "    sim_with_norms = similarities_norms(model_embd, results, key, norms, similarity_metric)\n",
    "    scores_norms[key] = sim_with_passages\n",
    "\n",
    "save_similarities(\"gemma\" + \"_sim.csv\", scores_passages)\n",
    "save_similarities(\"gemma\" + \"_sim_w_norms.csv\", scores_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PMtj3oAHqgR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
